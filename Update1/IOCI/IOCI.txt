@title IOCI
@description Estima el índice de congruencia item-objetivo
@param x dataframe, con las columnas asignadas a cada juez, y las filas asignada a cada ítem evaluado.
@param conf.level nivel de confianza para los intervalos de confianza (ex., .90, .95, .99)
@param cut point Específico rating desde el cual el ítem es considerado válido (o relevante, claro, etc.)
@details Estima el coeficiente CVR (Lawshe, 1975), e intervalos de confianza asimétricos (Wilson, 1927; Penfield & Giacobbi, 2004). Los resultados deberían ser complementados por un estimador de variabilidad o acuerdo entre los jueces.

@return dataframe con coeficientes CVR para todos los items analizados (con ajuste y sin ajuste por chance agreement), intervalos de confianza y número de jueces para cada coeficiente calculado

@examples
#Cargar datos del ejemplo ficticio 1 (Ej1): x jueces, y XX items evaluados por los jueces, sin datos perdidos.

data(Ej1)

vaiken(Ej1, ...)

@details
La función CVR calcula el content validity ratio (CVR), propuesto por Lashe (1975). Se asume que los ítems fueron calificados en tres categorías: No importante, útil pero no esencial, esencial. CVR dicotomiza cada calificación, y arroja la proporción de jueces que consideraron al ítem como esencial. 
El punto de corte usual para el CVR, para identificar ítems esenciales, debería estar ubicado en el ratin más alto posible; es decir, en una escala de 0 a 2, o 1 a 3, el punto de corte es 3 o 3, respectivamente.
El usuario debe tomar en cuenta que el índice calculado por la función CVR es conceptual y computacionalmente diferente al CVI referido en varios autores (Lindell, & Brandt, 1999; Tristán, 2008), que estima la validez de contenido del instrumento total. Pero CVR es similar al CVI, propuesto por Martuza (1977), pero asociado frecuentemente a otros investigadores (Polit, & Beck, 2006), por ejemplo, Lynn (1986), Davis (1992), Waltz & Bausell (1981), entre otros.
Para la interpretación, el output reporta el "Criterio Tristan (2008)", modificación propuesta por Tristan (2008) para establecer el mínimo CVR (CVR > .5823) desde el cual identificar ítems con validez de contenido.



http://www.r-tutor.com/elementary-statistics/probability-distributions/binomial-distribution
pbinom()

@references
*https://www.researchgate.net/publication/275556443_Critical_Values_for_Lawshe%27s_Content_Validity_Ratio

Davis, L.L. (1992). Instrument review: Getting the most from your panel of experts. Applied Nursing Research, 5, 194–197

Lawshe, C. H. (1975). A quantitative approach to content validity. Personnel psychology, 28, 563–575.

Lindell, M. K., & Brandt, C. J. (1999). Assessing interrater agreement on the job relevance of a test: A comparison of CVI, T, rWG(J)}, and r*WG(J)} indexes. Journal of  Applied Psychology, 84(4), 640–647. https://doi.org/10.1037/0021-9010.84.4.640

Lynn, M.R. (1986). Determination and quantification of content validity. Nursing Research, 35, 382–385.

Martuza, V.R. (1977). Applying norm-referenced and criterion-referenced measurement in education. Boston: Allyn & Bacon 

Polit, D. F., & Beck, C. T. (2006). The content validity index: are you sure you know what's being reported? Critique and recommendations. Research in nursing & health, 29(5), 489–497. https://doi.org/10.1002/nur.20147

Tristán, López, A. (2008). Modificación al modelo de Lawshe para el dictamen cuantitativo de la validez de contenido de un instrumento objetivo. Avances en Medición, 6, 37–48.

Waltz, C.F., & Bausell, R.B. (1981). Nursing research: Design, statistics, and computer analysis. Philadelphia: F. A. Davis.

Wilson, F. R., Pan, W., & Schumsky, D. A. (2012). Recalculation of the critical values for Lawshe’s content validity ratio. Measurement and Evaluation in Counseling and Development, 45, 197–210. doi:10.1177/0748175612440286
